{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EX3.regress_with_gradient3_lasso_iris.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"ZG4fxaUut8_u","colab_type":"text"},"cell_type":"markdown","source":["## 다항 변수에 대한 regression. 다항 회귀 분석"]},{"metadata":{"id":"LZ75NXIg27L8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SXKRqZBtx13_","colab_type":"code","colab":{}},"cell_type":"code","source":["def prn_shape(*args):\n","  print(' '.join([str(arg.shape) for arg in args]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L-i9gZNt26_W","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HL2ysGuMJo-t","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"_JVEjBCDiBhu","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from sklearn import datasets\n","iris = datasets.load_iris()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OPPekwtVwBOx","colab_type":"code","colab":{}},"cell_type":"code","source":["X = iris.data\n","Y = iris.target\n","Y = Y.reshape((-1, 1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zn5UfsnnuGQR","colab_type":"code","outputId":"468289a1-810e-425a-9ea6-44f36599079d","executionInfo":{"status":"ok","timestamp":1553081287572,"user_tz":-540,"elapsed":705,"user":{"displayName":"한대희","photoUrl":"","userId":"17475105266749362233"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["NUM = 100\n","Xtr = X[:NUM]\n","Ytr = Y[:NUM]\n","Xte = X[NUM:]\n","Yte = Y[NUM:]\n","print(Xtr.shape)\n","print(Xte.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(100, 4)\n","(50, 4)\n"],"name":"stdout"}]},{"metadata":{"id":"Q2Yf-_VQteOE","colab_type":"code","colab":{}},"cell_type":"code","source":["def rmse(arr1, arr2):\n","    return np.sqrt(np.mean((arr1-arr2)**2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lefyeSPUxsdZ","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# 주어진 모델로 실행하고, 결과 성능 출력하기\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","def exe_regression(model, Xtr, Ytr, Xte, Yte):\n","  prn_shape(Xtr, Ytr, Xte, Yte)\n","  model.fit(Xtr, Ytr)\n","  Y2 = model.predict(Xte)\n","  #print('Y2.shape', Y2.shape)\n","  rmse_v = rmse(Yte, Y2)\n","  print(\"RMSE: %.4f\" % (rmse_v))\n","  print(\"MSE: %.4f\" % mean_squared_error(Yte, Y2))\n","  print('R2: %.4f' % r2_score(Yte, Y2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Np6V9ZQ1VqiR","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","Gradient Descent 만들기\n","\"\"\"\n","def my_regrssion_with_gr(X, Y, debug=False):\n","  m = X.shape[0]\n","  dim = X.shape[1]\n","  \n","  lr = 0.003 # learning rate (eta)\n","  epochs = 30000\n","  alpha = .5\n","  W = np.random.randn(dim, 1)\n","  for i in range(epochs):     \n","      y2 = np.matmul(X, W) # y2 == predicted y\n","      err = y2 - Y # error, loss, residual (오차)\n","      #print(W.shape,X.shape, Y.shape, tmp.shape)\n","      grad = np.matmul(X.T, err) \n","      #print(tmp2.shape)\n","      gradients = float(2/m) * grad  # mean of gradients\n","      get_sign = lambda x: 1 if x > 0 else -1 if x < 0 else 0\n","      sign_of_W = np.array([get_sign(w) for w in W])\n","      #print('DEBUG', gradients.shape, sign_of_W.shape)\n","      gradients += alpha * sign_of_W.reshape((-1, 1))\n","      #print(gradients.shape)\n","      W = W - lr * gradients\n","      sum_of_each_grad = np.sum(np.abs(gradients))\n","      if sum_of_each_grad < 0.00004:\n","        print('Stop at epoch', i)\n","        break\n","      #break\n","  return W\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KGFfqNGcuos-","colab_type":"code","colab":{}},"cell_type":"code","source":["### 내 regression 클래스 만들기\n","class MyRegressWithGradientDescent(object):    \n","  def fit(self, X, Y):\n","    rows = X.shape[0] # X.shape[0] - 행의 갯수\n","    X = X.reshape((rows, -1)) # 1차원벡터인 경우, 행열로 변환\n","    Y = Y.reshape((rows, -1)) # 1차원벡터인 경우, 행열로 변환\n","    \n","    # bias 에 해당하는 [1,1,1, ..,1] 칼럼을 X에 추가한다.\n","    Xb = np.append(X, np.ones((rows, 1)), axis=1)\n","    self.w = my_regrssion_with_gr(Xb, Y)\n","    print('W', self.w)\n","    \n","  def predict(self, X):\n","    rows = X.shape[0] # X.shape[0] - 행의 갯수\n","    Xb = np.append(X, np.ones((rows, 1)), axis=1)\n","    pred = np.matmul(Xb, self.w)\n","    return pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SNIX7BwiWs9k","colab_type":"code","outputId":"9551f04f-7e87-4c35-e169-6b0954c5eed6","executionInfo":{"status":"ok","timestamp":1553081290254,"user_tz":-540,"elapsed":2314,"user":{"displayName":"한대희","photoUrl":"","userId":"17475105266749362233"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","\n","mymodel = MyRegressWithGradientDescent()\n","skmodel = LinearRegression()\n","\n","print('=== My Regression')\n","exe_regression(mymodel, Xtr, Ytr, Xte, Yte)\n","\n","\n","print('=== scikit-learn Regression')\n","exe_regression(skmodel, Xtr, Ytr, Xte, Yte)\n","print('W', skmodel.coef_, skmodel.intercept_)\n","\n","  "],"execution_count":18,"outputs":[{"output_type":"stream","text":["=== My Regression\n","(100, 4) (100, 1) (50, 4) (50, 1)\n","W [[-0.00144631]\n"," [-0.00104962]\n"," [ 0.18429087]\n"," [ 0.00169068]\n"," [-0.00052528]]\n","RMSE: 0.9916\n","MSE: 0.9833\n","R2: 0.0000\n","=== scikit-learn Regression\n","(100, 4) (100, 1) (50, 4) (50, 1)\n","RMSE: 0.6191\n","MSE: 0.3833\n","R2: 0.0000\n","W [[-0.02848968 -0.16819751  0.20313089  0.28785017]] [0.36970342]\n"],"name":"stdout"}]},{"metadata":{"id":"9DPQB69JU81c","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}